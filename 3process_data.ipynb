{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing Script\n",
    "\n",
    "This notebook handles two tasks:\n",
    "1. Clipping global phytoplankton NetCDF files to the Nile Delta region.\n",
    "2. Exporting turbidity maps (NDTI) from Landsat 7 imagery using Google Earth Engine.\n",
    "\n",
    "It prepares datasets for use in CNN training and prediction steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Clipping Phytoplankton NetCDFs and Generating Diatom Maps ---\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-01.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-02.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-03.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-04.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-05.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-06.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-07.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-08.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-09.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-10.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-11.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-12.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-13.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-14.nc\n",
      "Clipped and saved: /home/user/MSc/Clean_Codebase/data/processed/phytoplankton/Nile_AIGD-PFT-2023-01-15.nc\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 128\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Clipping Phytoplankton NetCDFs and Generating Diatom Maps ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 128\u001b[0m     \u001b[43mclip_phytoplankton\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Exporting NDTI GeoTIFFs from GEE ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    131\u001b[0m     export_ndti_gee()\n",
      "Cell \u001b[0;32mIn[1], line 60\u001b[0m, in \u001b[0;36mclip_phytoplankton\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m     lon_slice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mslice\u001b[39m(lon_min, lon_max)\n\u001b[1;32m     59\u001b[0m subset \u001b[38;5;241m=\u001b[39m ds\u001b[38;5;241m.\u001b[39msel(lat\u001b[38;5;241m=\u001b[39mlat_slice, lon\u001b[38;5;241m=\u001b[39mlon_slice)\n\u001b[0;32m---> 60\u001b[0m \u001b[43msubset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClipped and saved: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m ds\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/core/dataset.py:2380\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[1;32m   2377\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   2378\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 2380\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mto_netcdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[return-value]  # mypy cannot resolve the overloads:(\u001b[39;49;00m\n\u001b[1;32m   2381\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2382\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2383\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2384\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2386\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2387\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2388\u001b[0m \u001b[43m    \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2389\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2390\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmultifile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2391\u001b[0m \u001b[43m    \u001b[49m\u001b[43minvalid_netcdf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minvalid_netcdf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2392\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauto_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauto_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2393\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/backends/api.py:1928\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf, auto_complex)\u001b[0m\n\u001b[1;32m   1923\u001b[0m \u001b[38;5;66;03m# TODO: figure out how to refactor this logic (here and in save_mfdataset)\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[38;5;66;03m# to avoid this mess of conditionals\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;66;03m# TODO: allow this work (setting up the file for writing array data)\u001b[39;00m\n\u001b[1;32m   1927\u001b[0m     \u001b[38;5;66;03m# to be parallelized with dask\u001b[39;00m\n\u001b[0;32m-> 1928\u001b[0m     \u001b[43mdump_to_store\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1929\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstore\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\n\u001b[1;32m   1930\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1931\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m autoclose:\n\u001b[1;32m   1932\u001b[0m         store\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/backends/api.py:1975\u001b[0m, in \u001b[0;36mdump_to_store\u001b[0;34m(dataset, store, writer, encoder, encoding, unlimited_dims)\u001b[0m\n\u001b[1;32m   1972\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder:\n\u001b[1;32m   1973\u001b[0m     variables, attrs \u001b[38;5;241m=\u001b[39m encoder(variables, attrs)\n\u001b[0;32m-> 1975\u001b[0m \u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck_encoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munlimited_dims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43munlimited_dims\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/backends/common.py:454\u001b[0m, in \u001b[0;36mAbstractWritableDataStore.store\u001b[0;34m(self, variables, attributes, check_encoding_set, writer, unlimited_dims)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m writer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    452\u001b[0m     writer \u001b[38;5;241m=\u001b[39m ArrayWriter()\n\u001b[0;32m--> 454\u001b[0m variables, attributes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_attributes(attributes)\n\u001b[1;32m    457\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_dimensions(variables, unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims)\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/backends/common.py:638\u001b[0m, in \u001b[0;36mWritableCFDataStore.encode\u001b[0;34m(self, variables, attributes)\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, variables, attributes):\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;66;03m# All NetCDF files get CF encoded by default, without this attempting\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     \u001b[38;5;66;03m# to write times, for example, would fail.\u001b[39;00m\n\u001b[0;32m--> 638\u001b[0m     variables, attributes \u001b[38;5;241m=\u001b[39m \u001b[43mcf_encoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattributes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    639\u001b[0m     variables \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    640\u001b[0m         k: ensure_dtype_not_object(v, name\u001b[38;5;241m=\u001b[39mk) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    641\u001b[0m     }\n\u001b[1;32m    642\u001b[0m     variables \u001b[38;5;241m=\u001b[39m {k: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_variable(v) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/conventions.py:784\u001b[0m, in \u001b[0;36mcf_encoder\u001b[0;34m(variables, attributes)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;66;03m# add encoding for time bounds variables if present.\u001b[39;00m\n\u001b[1;32m    782\u001b[0m _update_bounds_encoding(variables)\n\u001b[0;32m--> 784\u001b[0m new_vars \u001b[38;5;241m=\u001b[39m {k: encode_cf_variable(v, name\u001b[38;5;241m=\u001b[39mk) \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Remove attrs from bounds variables (issue #2921)\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m new_vars\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/conventions.py:784\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;66;03m# add encoding for time bounds variables if present.\u001b[39;00m\n\u001b[1;32m    782\u001b[0m _update_bounds_encoding(variables)\n\u001b[0;32m--> 784\u001b[0m new_vars \u001b[38;5;241m=\u001b[39m {k: \u001b[43mencode_cf_variable\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m variables\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m    786\u001b[0m \u001b[38;5;66;03m# Remove attrs from bounds variables (issue #2921)\u001b[39;00m\n\u001b[1;32m    787\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m new_vars\u001b[38;5;241m.\u001b[39mvalues():\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/conventions.py:102\u001b[0m, in \u001b[0;36mencode_cf_variable\u001b[0;34m(var, needs_copy, name)\u001b[0m\n\u001b[1;32m     90\u001b[0m ensure_not_multiindex(var, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m coder \u001b[38;5;129;01min\u001b[39;00m [\n\u001b[1;32m     93\u001b[0m     CFDatetimeCoder(),\n\u001b[1;32m     94\u001b[0m     CFTimedeltaCoder(),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    100\u001b[0m     variables\u001b[38;5;241m.\u001b[39mBooleanCoder(),\n\u001b[1;32m    101\u001b[0m ]:\n\u001b[0;32m--> 102\u001b[0m     var \u001b[38;5;241m=\u001b[39m \u001b[43mcoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attr_name \u001b[38;5;129;01min\u001b[39;00m CF_RELATED_DATA:\n\u001b[1;32m    105\u001b[0m     pop_to(var\u001b[38;5;241m.\u001b[39mencoding, var\u001b[38;5;241m.\u001b[39mattrs, attr_name)\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/coding/times.py:1305\u001b[0m, in \u001b[0;36mCFDatetimeCoder.encode\u001b[0;34m(self, variable, name)\u001b[0m\n\u001b[1;32m   1303\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, variable: Variable, name: T_Name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Variable:\n\u001b[1;32m   1304\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39missubdtype(\n\u001b[0;32m-> 1305\u001b[0m         \u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241m.\u001b[39mdtype, np\u001b[38;5;241m.\u001b[39mdatetime64\n\u001b[1;32m   1306\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m contains_cftime_datetimes(variable):\n\u001b[1;32m   1307\u001b[0m         dims, data, attrs, encoding \u001b[38;5;241m=\u001b[39m unpack_for_encoding(variable)\n\u001b[1;32m   1309\u001b[0m         units \u001b[38;5;241m=\u001b[39m encoding\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munits\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/core/variable.py:415\u001b[0m, in \u001b[0;36mVariable.data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\n\u001b[1;32m    414\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, indexing\u001b[38;5;241m.\u001b[39mExplicitlyIndexed):\n\u001b[0;32m--> 415\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalues\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/core/indexing.py:835\u001b[0m, in \u001b[0;36mMemoryCachedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 835\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_ensure_cached\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39mget_duck_array()\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/core/indexing.py:832\u001b[0m, in \u001b[0;36mMemoryCachedArray._ensure_cached\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_ensure_cached\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 832\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray \u001b[38;5;241m=\u001b[39m as_indexable(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/core/indexing.py:789\u001b[0m, in \u001b[0;36mCopyOnWriteArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mget_duck_array\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 789\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_duck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/core/indexing.py:652\u001b[0m, in \u001b[0;36mLazilyIndexedArray.get_duck_array\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    648\u001b[0m     array \u001b[38;5;241m=\u001b[39m apply_indexer(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39marray, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkey)\n\u001b[1;32m    649\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    650\u001b[0m     \u001b[38;5;66;03m# If the array is not an ExplicitlyIndexedNDArrayMixin,\u001b[39;00m\n\u001b[1;32m    651\u001b[0m     \u001b[38;5;66;03m# it may wrap a BackendArray so use its __getitem__\u001b[39;00m\n\u001b[0;32m--> 652\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;66;03m# self.array[self.key] is now a numpy array when\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;66;03m# self.array is a BackendArray subclass\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;66;03m# and self.key is BasicIndexer((slice(None, None, None),))\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;66;03m# so we need the explicit check for ExplicitlyIndexed\u001b[39;00m\n\u001b[1;32m    658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(array, ExplicitlyIndexed):\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:103\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[0;32m--> 103\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexplicit_indexing_adapter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexing\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexingSupport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOUTER\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/core/indexing.py:1013\u001b[0m, in \u001b[0;36mexplicit_indexing_adapter\u001b[0;34m(key, shape, indexing_support, raw_indexing_method)\u001b[0m\n\u001b[1;32m    991\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Support explicit indexing by delegating to a raw indexing method.\u001b[39;00m\n\u001b[1;32m    992\u001b[0m \n\u001b[1;32m    993\u001b[0m \u001b[38;5;124;03mOuter and/or vectorized indexers are supported by indexing a second time\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03mIndexing result, in the form of a duck numpy-array.\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1012\u001b[0m raw_key, numpy_indices \u001b[38;5;241m=\u001b[39m decompose_indexer(key, shape, indexing_support)\n\u001b[0;32m-> 1013\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mraw_indexing_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraw_key\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuple\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numpy_indices\u001b[38;5;241m.\u001b[39mtuple:\n\u001b[1;32m   1015\u001b[0m     \u001b[38;5;66;03m# index the loaded np.ndarray\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m     indexable \u001b[38;5;241m=\u001b[39m NumpyIndexingAdapter(result)\n",
      "File \u001b[0;32m~/anaconda3/envs/msc1_new/lib/python3.10/site-packages/xarray/backends/netCDF4_.py:116\u001b[0m, in \u001b[0;36mNetCDF4ArrayWrapper._getitem\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdatastore\u001b[38;5;241m.\u001b[39mlock:\n\u001b[1;32m    115\u001b[0m         original_array \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_array(needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 116\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43mgetitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43moriginal_array\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    117\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    118\u001b[0m     \u001b[38;5;66;03m# Catch IndexError in netCDF4 and return a more informative\u001b[39;00m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;66;03m# error message.  This is most often called when an unsorted\u001b[39;00m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# indexer is used before the data is loaded from disk.\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe indexing operation you are attempting to perform \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis not valid on netCDF4.Variable object. Try loading \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myour data into memory first by calling .load().\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m     )\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "process_data.py\n",
    "\n",
    "1. Clips global phytoplankton NetCDF data to Nile Delta using nile_polygon.geojson.\n",
    "2. Saves daily normalized Diatom (Diat) maps as PNGs.\n",
    "3. Initiates Earth Engine exports of daily NDTI turbidity GeoTIFFs using Landsat 7.\n",
    "\n",
    "Run this script from the root directory of the project (where nile_polygon.geojson is located).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import mapping\n",
    "\n",
    "# Directories\n",
    "RAW_PHYTO_DIR = \"/home/user/MSc/Clean_Codebase/data/raw/phytoplankton/\"\n",
    "PROC_PHYTO_DIR = \"/home/user/MSc/Clean_Codebase/data/processed/phytoplankton/\"\n",
    "DIAT_IMG_DIR = \"/home/user/MSc/Clean_Codebase/data/processed/diatom_pngs/\"\n",
    "os.makedirs(PROC_PHYTO_DIR, exist_ok=True)\n",
    "os.makedirs(DIAT_IMG_DIR, exist_ok=True)\n",
    "\n",
    "# Load polygon\n",
    "polygon_path = \"nile_polygon.geojson\"\n",
    "gdf = gpd.read_file(polygon_path)\n",
    "polygon = gdf.geometry.iloc[0]\n",
    "crs = gdf.crs or \"EPSG:4326\"\n",
    "\n",
    "\n",
    "def clip_phytoplankton():\n",
    "    # Define bounding box manually\n",
    "    lat_min, lat_max = 31.0, 34.0\n",
    "    lon_min, lon_max = 28.0, 33.0\n",
    "\n",
    "    for fname in os.listdir(RAW_PHYTO_DIR):\n",
    "        if fname.endswith(\".nc\"):\n",
    "            in_path = os.path.join(RAW_PHYTO_DIR, fname)\n",
    "            out_path = os.path.join(PROC_PHYTO_DIR, f\"Nile_{fname}\")\n",
    "            try:\n",
    "                ds = xr.open_dataset(in_path)\n",
    "\n",
    "                # Get lat/lon orientation\n",
    "                lat_vals = ds.lat.values\n",
    "                lon_vals = ds.lon.values\n",
    "\n",
    "                if lat_vals[0] > lat_vals[-1]:  # descending\n",
    "                    lat_slice = slice(lat_max, lat_min)\n",
    "                else:\n",
    "                    lat_slice = slice(lat_min, lat_max)\n",
    "\n",
    "                if lon_vals[0] > lon_vals[-1]:  # descending\n",
    "                    lon_slice = slice(lon_max, lon_min)\n",
    "                else:\n",
    "                    lon_slice = slice(lon_min, lon_max)\n",
    "\n",
    "                subset = ds.sel(lat=lat_slice, lon=lon_slice)\n",
    "                subset.to_netcdf(out_path)\n",
    "                print(f\"Clipped and saved: {out_path}\")\n",
    "                ds.close()\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {fname}: {e}\")\n",
    "\n",
    "\n",
    "# 2. GEE Landsat NDTI Export\n",
    "def export_ndti_gee():\n",
    "    import ee\n",
    "    from datetime import datetime, timedelta\n",
    "\n",
    "    ee.Initialize(project='earthproject145')\n",
    "\n",
    "    # Load GeoJSON polygon for Earth Engine\n",
    "    with open(polygon_path, \"r\") as f:\n",
    "        geojson_data = json.load(f)\n",
    "\n",
    "    if \"coordinates\" in geojson_data:\n",
    "        user_polygon = ee.Geometry.Polygon(geojson_data[\"coordinates\"], geodesic=False)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid GeoJSON format.\")\n",
    "\n",
    "    def apply_scale_factors(image):\n",
    "        optical = image.select(['SR_B1', 'SR_B2', 'SR_B3', 'SR_B4', 'SR_B5', 'SR_B7']).multiply(0.0000275).add(-0.2)\n",
    "        return image.addBands(optical, None, True)\n",
    "\n",
    "    start_date = datetime(2023, 1, 1)\n",
    "    end_date = datetime(2023, 2, 1)\n",
    "\n",
    "    current_date = start_date\n",
    "    while current_date < end_date:\n",
    "        next_date = current_date + timedelta(days=1)\n",
    "        landsat = ee.ImageCollection(\"LANDSAT/LE07/C02/T1_L2\") \\\n",
    "            .filterBounds(user_polygon) \\\n",
    "            .filterDate(current_date.strftime('%Y-%m-%d'), next_date.strftime('%Y-%m-%d')) \\\n",
    "            .filter(ee.Filter.lt(\"CLOUD_COVER\", 10)) \\\n",
    "            .map(apply_scale_factors)\n",
    "\n",
    "        if landsat.size().getInfo() > 0:\n",
    "            image = landsat.median()\n",
    "            ndti = image.normalizedDifference([\"SR_B4\", \"SR_B3\"]).rename(\"NDTI\")\n",
    "            ndwi = image.normalizedDifference([\"SR_B3\", \"SR_B5\"]).rename(\"NDWI\")\n",
    "            water_mask = ndwi.gt(0).clip(user_polygon)\n",
    "            ndti_masked = ndti.updateMask(water_mask).clip(user_polygon)\n",
    "\n",
    "            task = ee.batch.Export.image.toDrive(\n",
    "                image=ndti_masked,\n",
    "                description=f\"Nile_Turbidity_{current_date.strftime('%Y-%m-%d')}\",\n",
    "                folder=\"Nile_Turbidity_Raw_GeoTIFF2\",\n",
    "                fileNamePrefix=f\"nile_turbidity_{current_date.strftime('%Y_%m_%d')}\",\n",
    "                region=user_polygon,\n",
    "                scale=30,\n",
    "                crs='EPSG:4326',\n",
    "                maxPixels=1e9,\n",
    "                fileFormat='GeoTIFF'\n",
    "            )\n",
    "            task.start()\n",
    "            print(f\"Started export for {current_date.strftime('%Y-%m-%d')}\")\n",
    "        else:\n",
    "            print(f\"No image on {current_date.strftime('%Y-%m-%d')}\")\n",
    "\n",
    "        current_date = next_date\n",
    "\n",
    "# MAIN\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"\\n--- Clipping Phytoplankton NetCDFs and Generating Diatom Maps ---\")\n",
    "    clip_phytoplankton()\n",
    "\n",
    "    print(\"\\n--- Exporting NDTI GeoTIFFs from GEE ---\")\n",
    "    export_ndti_gee()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "The phytoplankton NetCDF data is subset to the specified lat/lon range and saved as smaller NetCDF files for efficient access. We rely on xarray for convenient slicing and NetCDF I/O​\n",
    "https://docs.xarray.dev/en/stable/user-guide/io.html#:~:text=netCDF\n",
    "\n",
    "For turbidity, we assume the raw GeoTIFFs are already focused on the Nile Delta region (e.g., exported from Google Earth Engine). The code includes placeholders to clip the raster with rasterio if needed. GeoTIFF is a common format for gridded raster data like satellite-derived turbidity​\n",
    "https://rasterio.readthedocs.io/#:~:text=Geographic%20information%20systems%20use%20GeoTIFF,satellite%20imagery%20and%20terrain%20models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msc1_new",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
